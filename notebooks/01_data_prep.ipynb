{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Source:\n",
    "- Public, anonymized e-commerce behavior logs\n",
    "- Monthly CSV files (2019-Oct, 2019-Nov)\n",
    "\n",
    "Goal:\n",
    "- Merge raw event logs\n",
    "- Enforce a clean data contract\n",
    "- Output a single experiment-ready dataset: clean_events.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\\raw\\2019-Oct.csv ...\n",
      "Loading data\\raw\\2019-Nov.csv ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(109950743, 8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "raw_path = Path(\"data/raw\")\n",
    "\n",
    "files = [\n",
    "    raw_path / \"2019-Oct.csv\",\n",
    "    raw_path / \"2019-Nov.csv\"\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for f in files:\n",
    "    print(f\"Loading {f} ...\")\n",
    "    df_part = pd.read_csv(\n",
    "        f,\n",
    "        usecols=[\n",
    "            \"event_time\", \"event_type\", \"product_id\",\n",
    "            \"category_code\", \"brand\", \"price\",\n",
    "            \"user_id\", \"user_session\"\n",
    "        ]\n",
    "    )\n",
    "    dfs.append(df_part)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time\n",
    "df[\"event_time\"] = pd.to_datetime(df[\"event_time\"], errors=\"coerce\")\n",
    "\n",
    "# numeric\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data\\raw\\2019-Oct.csv\n",
      "  chunks processed: 10, rows written so far: 5,000,000\n",
      "  chunks processed: 20, rows written so far: 9,999,999\n",
      "  chunks processed: 30, rows written so far: 14,999,999\n",
      "  chunks processed: 40, rows written so far: 19,999,999\n",
      "  chunks processed: 50, rows written so far: 24,999,999\n",
      "  chunks processed: 60, rows written so far: 29,999,999\n",
      "  chunks processed: 70, rows written so far: 34,999,998\n",
      "  chunks processed: 80, rows written so far: 39,999,998\n",
      "Processing: data\\raw\\2019-Nov.csv\n",
      "  chunks processed: 10, rows written so far: 47,448,762\n",
      "  chunks processed: 20, rows written so far: 52,448,762\n",
      "  chunks processed: 30, rows written so far: 57,448,760\n",
      "  chunks processed: 40, rows written so far: 62,448,760\n",
      "  chunks processed: 50, rows written so far: 67,448,758\n",
      "  chunks processed: 60, rows written so far: 72,448,758\n",
      "  chunks processed: 70, rows written so far: 77,448,758\n",
      "  chunks processed: 80, rows written so far: 82,448,758\n",
      "  chunks processed: 90, rows written so far: 87,448,758\n",
      "  chunks processed: 100, rows written so far: 92,448,758\n",
      "  chunks processed: 110, rows written so far: 97,448,758\n",
      "  chunks processed: 120, rows written so far: 102,448,754\n",
      "  chunks processed: 130, rows written so far: 107,448,753\n",
      "Done. Saved: data\\clean_events.csv | rows written: 109,950,731\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "raw_path = Path(\"data/raw\")\n",
    "files = [raw_path / \"2019-Oct.csv\", raw_path / \"2019-Nov.csv\"]\n",
    "\n",
    "out_path = Path(\"data/clean_events.csv\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "usecols = [\n",
    "    \"event_time\", \"event_type\", \"product_id\",\n",
    "    \"category_code\", \"brand\", \"price\",\n",
    "    \"user_id\", \"user_session\"\n",
    "]\n",
    "\n",
    "valid_events = {\"view\", \"cart\", \"purchase\"}\n",
    "\n",
    "# 调大/调小：越大越快但越吃内存；推荐先 500_000\n",
    "CHUNKSIZE = 500_000\n",
    "\n",
    "# 如果之前跑过，先删旧文件，避免重复追加\n",
    "if out_path.exists():\n",
    "    out_path.unlink()\n",
    "\n",
    "total_written = 0\n",
    "\n",
    "for f in files:\n",
    "    print(f\"Processing: {f}\")\n",
    "    reader = pd.read_csv(f, usecols=usecols, chunksize=CHUNKSIZE)\n",
    "\n",
    "    for i, chunk in enumerate(reader, start=1):\n",
    "        # 基础类型转换\n",
    "        chunk[\"event_time\"] = pd.to_datetime(chunk[\"event_time\"], errors=\"coerce\")\n",
    "        chunk[\"price\"] = pd.to_numeric(chunk[\"price\"], errors=\"coerce\")\n",
    "\n",
    "        # event_type 只做最小规范化\n",
    "        chunk[\"event_type\"] = (\n",
    "            chunk[\"event_type\"]\n",
    "            .astype(\"string\")\n",
    "            .str.lower()\n",
    "            .str.strip()\n",
    "        )\n",
    "\n",
    "        # 过滤：只保留漏斗事件\n",
    "        chunk = chunk[chunk[\"event_type\"].isin(valid_events)]\n",
    "\n",
    "        # 必要字段非空\n",
    "        chunk = chunk.dropna(subset=[\"user_id\", \"user_session\", \"event_time\", \"event_type\"])\n",
    "\n",
    "        # price：允许缺失，但不允许负数\n",
    "        chunk = chunk[(chunk[\"price\"].isna()) | (chunk[\"price\"] >= 0)]\n",
    "\n",
    "        # 写出：append 模式（header 只写一次）\n",
    "        chunk.to_csv(out_path, mode=\"a\", header=(total_written == 0), index=False)\n",
    "\n",
    "        total_written += len(chunk)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"  chunks processed: {i}, rows written so far: {total_written:,}\")\n",
    "\n",
    "print(f\"Done. Saved: {out_path} | rows written: {total_written:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
